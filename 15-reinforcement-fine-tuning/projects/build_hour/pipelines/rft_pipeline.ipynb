{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9079bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "022798a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import json, pathlib, sys, os\n",
    "from openai import AsyncOpenAI\n",
    "from openai.types.fine_tuning import ReinforcementHyperparameters\n",
    "from openai.lib._pydantic import to_strict_json_schema "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47b5a0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "HERE = pathlib.Path().resolve()\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Locate shared root (the folder that contains both `utils` and your project)\n",
    "# It climbs up until it finds a `utils/` directory or stops at filesystem root.\n",
    "# ---------------------------------------------------------------------------\n",
    "ROOT = HERE\n",
    "while ROOT != ROOT.parent and not (ROOT / \"utils\").exists():\n",
    "    ROOT = ROOT.parent\n",
    "\n",
    "if not (ROOT / \"utils\").exists():\n",
    "    raise RuntimeError(\n",
    "        f\"Could not find 'utils' directory above {HERE}. \"\n",
    "        \"Check your project structure or adjust the path resolution logic.\"\n",
    "    )\n",
    "\n",
    "if str(ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(ROOT))\n",
    "print(f\"✅ Added to sys.path: {ROOT}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Infer project name (parent of pipelines/ or notebooks/)\n",
    "# e.g., .../projects/<project>/notebooks/... -> <project>\n",
    "# ---------------------------------------------------------------------------\n",
    "project_name = HERE.parent.name\n",
    "os.environ.setdefault(\"PROJECT\", project_name)\n",
    "print(f\"✅ Project name set to: {project_name}\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Load project-specific environment variables\n",
    "# ---------------------------------------------------------------------------\n",
    "env_path = HERE.parent / \".env\"\n",
    "if env_path.exists():\n",
    "    load_dotenv(env_path, override=True)\n",
    "    print(f\"✅ Loaded .env from: {env_path}\")\n",
    "else:\n",
    "    print(\"⚠️ No .env file found, relying on existing environment variables.\")\n",
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Ensure the OpenAI API key is available\n",
    "# ---------------------------------------------------------------------------\n",
    "api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "if not api_key:\n",
    "    raise RuntimeError(\n",
    "        \"OPENAI_API_KEY not found. Add it to your .env file or export it before running.\"\n",
    "    )\n",
    "print(\"✅ OpenAI API key detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb1fe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Project Imports (now should work everywhere)\n",
    "# ---------------------------------------------------------------------------\n",
    "from utils import build_rft_jsonl, get_or_upload_file, load_prompt, load_saved_grader, create_rft_job\n",
    "from utils.project_paths import datasets_root, project_root\n",
    "from utils.grader_utils import load_saved_grader\n",
    "\n",
    "# Ensure structured_outputs can be imported\n",
    "_cust_root = project_root()\n",
    "if str(_cust_root) not in sys.path:\n",
    "    sys.path.append(str(_cust_root))\n",
    "\n",
    "\n",
    "print(\"✅ Utils imported successfully.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e5bddfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure USER_FIELD and PROMPT_NAME --------------------------------------\n",
    "USER_FIELD = \"text_input\"\n",
    "PROMPT_NAME = \"v7\"\n",
    "DATASET_NAME = project_name\n",
    "\n",
    "prompt_obj = load_prompt(DATASET_NAME, PROMPT_NAME, prompt_type=\"developer\")\n",
    "assert prompt_obj, \"Prompt not found\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3b03e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect splits present in data/\n",
    "client_kwargs = {\"api_key\": api_key}\n",
    "proj_id = os.getenv(\"OPENAI_PROJECT_ID\")\n",
    "if proj_id:\n",
    "    client_kwargs[\"project\"] = proj_id\n",
    "\n",
    "client = AsyncOpenAI(**client_kwargs)\n",
    "\n",
    "splits = [\"train\", \"val\"]\n",
    "train_file_id = None\n",
    "val_file_id = None\n",
    "for split in splits:\n",
    "    data_path = next(datasets_root().glob(f\"*_{split}.jsonl\"))\n",
    "    items = [json.loads(l) for l in data_path.read_text().splitlines()]\n",
    "    rft_path = await build_rft_jsonl(prompt_obj.text, prompt_obj.id, items, split=split, user_field=USER_FIELD)\n",
    "    file_id = await get_or_upload_file(client, rft_path, purpose=\"fine-tune\")\n",
    "    print(f\"[RFT] Split {split}: file_id = {file_id}\")\n",
    "    if split == \"train\":\n",
    "        train_file_id = file_id\n",
    "    elif split in {\"val\", \"valid\", \"validation\"}:\n",
    "        val_file_id = file_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b5f4184",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the response format\n",
    "from structured_outputs.base_models import Level1Codes\n",
    "\n",
    "schema = to_strict_json_schema(Level1Codes)\n",
    "RESPONSE_FORMAT = dict(\n",
    "    type=\"json_schema\",\n",
    "    json_schema={\n",
    "        \"name\": Level1Codes.__name__,\n",
    "        \"schema\": schema,\n",
    "        \"strict\": True,\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b997eac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load grader for RFT (Param object is sufficient)\n",
    "GRADER = load_saved_grader(DATASET_NAME, \"level1_f1_multi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a263af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "API_KEY = os.environ[\"OPENAI_API_KEY\"]\n",
    "HEADERS = {\"Authorization\": f\"Bearer {API_KEY}\"}\n",
    "\n",
    "# Validate a grader configuration for fine-tuning\n",
    "payload = {\"grader\": GRADER}\n",
    "try:\n",
    "    response = requests.post(\n",
    "        \"https://api.openai.com/v1/fine_tuning/alpha/graders/validate\",\n",
    "        json=payload,\n",
    "        headers=HEADERS,\n",
    "    )\n",
    "    response.raise_for_status()\n",
    "    print(\"Grader validated\")\n",
    "except requests.exceptions.RequestException as e:\n",
    "    print(f\"Error validating grader: {e}\")\n",
    "    if 'response' in locals():\n",
    "        print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f000e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyper-parameters for RFT fine-tuning -----------------------------\n",
    "HPARAMS = ReinforcementHyperparameters(\n",
    "    n_epochs=15,\n",
    "    batch_size=16,\n",
    "    reasoning_effort=\"low\",\n",
    "    eval_samples=3,\n",
    "    compute_multiplier=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04e3fd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create RFT job\n",
    "job_id = await create_rft_job(\n",
    "    client=client,\n",
    "    train_file_id=train_file_id,\n",
    "    val_file_id=val_file_id,\n",
    "    grader=GRADER,\n",
    "    base_model=\"o4-mini-2025-04-16\",\n",
    "    hp=HPARAMS,\n",
    "    suffix=f\"rft-{project_name}-prompt-{PROMPT_NAME}\",\n",
    "    seed=42,\n",
    "    response_format=RESPONSE_FORMAT,\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
