{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3efbe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"balanced_sampling_150.py – create a *150-example* balanced dataset and split into train/val.\n",
    "\n",
    "Steps:\n",
    "1. Load source records (with EuroVoc descriptors).\n",
    "2. Determine the smallest per-label cap that yields ≥ 150 distinct examples with\n",
    "   the greedy balanced sampler (rare labels first).\n",
    "3. If more than 150 are selected, randomly drop extras to reach 150 exactly.\n",
    "4. Split 2/3, 1/3 into train/val (shuffled, stratification not re-enforced).\n",
    "5. Write JSONL files and show distribution summaries/plots for both splits.\n",
    "\"\"\"\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import json\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from pathlib import Path\n",
    "from typing import List\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d152fbdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Configuration\n",
    "# ---------------------------------------------------------------------------\n",
    "DATA_PATH = Path(\"data/dev_with_descriptors.jsonl\")\n",
    "OUT_TRAIN = Path(\"data/build_hour_train.jsonl\")\n",
    "OUT_val = Path(\"data/build_hour_val.jsonl\")\n",
    "\n",
    "SEED = 1\n",
    "random.seed(SEED)\n",
    "\n",
    "TARGET_TOTAL = 150  # total examples across train+val\n",
    "TRAIN_RATIO = 0.67   # fraction sent to train; rest to val\n",
    "LABEL_FIELD = \"level_1\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46a0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ---------------------------------------------------------------------------\n",
    "# Utilities (re-used from previous script)\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "def load_records(path: Path) -> List[dict]:\n",
    "    with path.open(\"r\", encoding=\"utf-8\") as f:\n",
    "        return [json.loads(line) for line in f]\n",
    "\n",
    "\n",
    "def gather_label_indices(records: List[dict], label_field: str) -> dict[str, List[int]]:\n",
    "    per_label: dict[str, List[int]] = defaultdict(list)\n",
    "    for idx, rec in enumerate(records):\n",
    "        for lbl in rec.get(\"eurovoc_concepts\", {}).get(label_field, []):\n",
    "            per_label[lbl].append(idx)\n",
    "    return per_label\n",
    "\n",
    "\n",
    "def greedy_balanced_sampling(\n",
    "    records: List[dict],\n",
    "    label_field: str,\n",
    "    cap: int,\n",
    "    already_selected: set[int] | None = None,\n",
    ") -> set[int]:\n",
    "    \"\"\"Greedy selection with per-label cap (see balanced_sampling.py for logic).\"\"\"\n",
    "    if already_selected is None:\n",
    "        already_selected = set()\n",
    "\n",
    "    per_label = gather_label_indices(records, label_field)\n",
    "    label_counts = Counter()\n",
    "    for idx in already_selected:\n",
    "        for lbl in records[idx].get(\"eurovoc_concepts\", {}).get(label_field, []):\n",
    "            label_counts[lbl] += 1\n",
    "\n",
    "    selected: set[int] = set(already_selected)\n",
    "    labels_sorted = sorted(per_label.keys(), key=lambda l: len(per_label[l]))\n",
    "\n",
    "    for lbl in labels_sorted:\n",
    "        if label_counts[lbl] >= cap:\n",
    "            continue\n",
    "        candidates = [i for i in per_label[lbl] if i not in selected]\n",
    "        random.shuffle(candidates)\n",
    "        for idx in candidates:\n",
    "            labels_idx = records[idx].get(\"eurovoc_concepts\", {}).get(label_field, [])\n",
    "            if all(label_counts[x] < cap for x in labels_idx):\n",
    "                selected.add(idx)\n",
    "                for x in labels_idx:\n",
    "                    label_counts[x] += 1\n",
    "                if label_counts[lbl] >= cap:\n",
    "                    break\n",
    "    return selected - already_selected\n",
    "\n",
    "\n",
    "def write_split(path: Path, indices: List[int], records: List[dict]) -> None:\n",
    "    \"\"\"Write dataset entries in the same schema used in exploration.py.\n",
    "\n",
    "    Each line is a JSON object:\n",
    "        { \"item\": { \"id\": \"<seq>\", \"text_input\": \"…\", \"reference_answer\": [..] } }\n",
    "    where <seq> is a zero-based index within the current split file.\n",
    "    \"\"\"\n",
    "\n",
    "    with path.open(\"w\", encoding=\"utf-8\") as f_out:\n",
    "        for new_id, idx in enumerate(indices):\n",
    "            rec = records[idx]\n",
    "            level1 = rec.get(\"eurovoc_concepts\", {}).get(\"level_1\", [])\n",
    "            obj = {\n",
    "                \"item\": {\n",
    "                    \"id\": str(new_id),\n",
    "                    \"text_input\": rec.get(\"text\", {}).get(\"en\", \"\"),\n",
    "                    \"reference_answer\": level1,\n",
    "                }\n",
    "            }\n",
    "            f_out.write(json.dumps(obj, ensure_ascii=False) + \"\\n\")\n",
    "    print(f\"Wrote {len(indices)} records → {path}\")\n",
    "\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "def plot_distribution(name: str, indices: List[int], records: List[dict], label_field: str) -> None:\n",
    "    # Count occurrences of each descriptor in the selected indices\n",
    "    counter = Counter()\n",
    "    for idx in indices:\n",
    "        counter.update(records[idx].get(\"eurovoc_concepts\", {}).get(label_field, []))\n",
    "\n",
    "    # Sort descriptors alphabetically (case-insensitive, descending)\n",
    "    sorted_items = sorted(counter.items(), key=lambda x: x[1])\n",
    "    descriptors, counts = zip(*sorted_items) if sorted_items else ([], [])\n",
    "\n",
    "    # Plot with Plotly using a single brand color (OpenAI blue), dark mode\n",
    "    bar_color = \"#0071cf\"\n",
    "    fig = go.Figure(\n",
    "        go.Bar(\n",
    "            x=list(counts),\n",
    "            y=list(descriptors),\n",
    "            orientation=\"h\",\n",
    "            marker=dict(color=bar_color),\n",
    "        )\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        title=f\"{name} – {label_field} frequencies\",\n",
    "        xaxis_title=\"Frequency\",\n",
    "        yaxis_title=\"\",\n",
    "        template=\"plotly_dark\",\n",
    "        height=700,\n",
    "        width=900,\n",
    "        yaxis=dict(automargin=True),\n",
    "        font=dict(family=\"Inter, sans-serif\", color=\"#FFFFFF\"),\n",
    "        plot_bgcolor=\"#111111\",\n",
    "        paper_bgcolor=\"#111111\",\n",
    "    )\n",
    "\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21d996ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ---------------------------------------------------------------------------\n",
    "# Interactive workflow\n",
    "# ---------------------------------------------------------------------------\n",
    "\n",
    "# 1. Load data\n",
    "records = load_records(DATA_PATH)\n",
    "per_label = gather_label_indices(records, LABEL_FIELD)\n",
    "print(f\"Loaded {len(records):,} records with {len(per_label)} unique {LABEL_FIELD} labels\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ee53a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Greedy balanced sampling to reach TARGET_TOTAL\n",
    "selected: set[int] = set()\n",
    "cap = 1\n",
    "\n",
    "while True:\n",
    "    new = greedy_balanced_sampling(records, LABEL_FIELD, cap, already_selected=selected)\n",
    "    selected.update(new)\n",
    "    print(f\"Cap={cap:<2}  => selected so far: {len(selected)}\")\n",
    "    if len(selected) >= TARGET_TOTAL or cap > 50:  # safety break\n",
    "        break\n",
    "    cap += 1\n",
    "\n",
    "# If overshoot, randomly drop extras to reach exactly TARGET_TOTAL\n",
    "if len(selected) > TARGET_TOTAL:\n",
    "    surplus = len(selected) - TARGET_TOTAL\n",
    "    selected = set(random.sample(list(selected), TARGET_TOTAL))\n",
    "    print(f\"Trimmed {surplus} excess examples to hit {TARGET_TOTAL}\")\n",
    "\n",
    "selected_list = sorted(selected)\n",
    "random.shuffle(selected_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8749f889",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Train / val split using custom quota-based stratification\n",
    "\n",
    "def deficit_stratified_split(indices: list[int], train_ratio: float) -> tuple[list[int], list[int]]:\n",
    "    \"\"\"Symmetric deficit-based multi-label stratification.\n",
    "\n",
    "    Chooses for each item the split (train or val) that currently has the\n",
    "    greater summed deficiency for that item's labels. Guarantees exact\n",
    "    train/val sizes and tends to equalize label distributions.\n",
    "    \"\"\"\n",
    "\n",
    "    rng_local = random.Random(SEED)\n",
    "\n",
    "    total = len(indices)\n",
    "    train_target_size = int(round(total * train_ratio))\n",
    "\n",
    "    # Compute per-label totals\n",
    "    total_counts: Counter[str] = Counter()\n",
    "    for idx in indices:\n",
    "        total_counts.update(records[idx].get(\"eurovoc_concepts\", {}).get(LABEL_FIELD, []))\n",
    "\n",
    "    # Desired counts per split\n",
    "    target_train = {lbl: int(round(cnt * train_ratio)) for lbl, cnt in total_counts.items()}\n",
    "    target_val = {lbl: total_counts[lbl] - target_train[lbl] for lbl in total_counts}\n",
    "\n",
    "    train_counts: Counter[str] = Counter()\n",
    "    val_counts: Counter[str] = Counter()\n",
    "    train, val = [], []\n",
    "\n",
    "    shuffled = indices.copy()\n",
    "    rng_local.shuffle(shuffled)\n",
    "\n",
    "    for idx in shuffled:\n",
    "        labels = records[idx].get(\"eurovoc_concepts\", {}).get(LABEL_FIELD, [])\n",
    "\n",
    "        # Compute deficits\n",
    "        train_def = sum(max(0, target_train[lbl] - train_counts[lbl]) for lbl in labels)\n",
    "        val_def = sum(max(0, target_val[lbl] - val_counts[lbl]) for lbl in labels)\n",
    "\n",
    "        choose_train = False\n",
    "        if len(train) >= train_target_size:\n",
    "            choose_train = False\n",
    "        elif len(val) >= total - train_target_size:\n",
    "            choose_train = True\n",
    "        else:\n",
    "            choose_train = train_def > val_def or (train_def == val_def and len(train) < train_target_size)\n",
    "\n",
    "        if choose_train:\n",
    "            train.append(idx)\n",
    "            train_counts.update(labels)\n",
    "        else:\n",
    "            val.append(idx)\n",
    "            val_counts.update(labels)\n",
    "\n",
    "    return sorted(train), sorted(val)\n",
    "\n",
    "train_indices, val_indices = deficit_stratified_split(selected_list, TRAIN_RATIO)\n",
    "\n",
    "print(\n",
    "    f\"Final sizes – Train: {len(train_indices)}, val: {len(val_indices)} (cap used = {cap})\"\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5233934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Write splits\n",
    "write_split(OUT_TRAIN, train_indices, records)\n",
    "write_split(OUT_val, val_indices, records)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2f699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Combined distribution (train + val)\n",
    "plot_distribution(\"All\", sorted(selected_list), records, LABEL_FIELD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86524cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
